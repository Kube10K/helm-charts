image:
  # -- (`string`) The Docker Image and Repository
  repository: k8s.gcr.io/autoscaling/cluster-autoscaler
  pullPolicy: IfNotPresent

  # -- (`string`) The image version we will run.
  tag:

# https://aws.github.io/aws-eks-best-practices/cluster-autoscaling/#vertically-autoscaling-the-cluster-autoscaler
podNanny:
  image:
    repository: k8s.gcr.io/autoscaling/addon-resizer
    tag: 1.8.14
    pullPolicy: IfNotPresent

  resources:
    limits:
      cpu: 300m
      memory: 200Mi
    requests:
      cpu: 300m
      memory: 200Mi

  args:
    # The time, in milliseconds, to poll the dependent container. (5m here)
    - --poll-period=300000

    # Make a change when we're 25% over or under-provisioned.
    # Under-provisioning by only 25% isn't generally that
    # critical.
    - --threshold=25

    # The goal here is to figure out how big we need to be
    # on an average day, and stay that big. We don't want
    # to scale up/down throughout the day based on load,
    # but instead just make sure we react as the cluster
    # grows. So we won't scale down more than every 36
    # hours. That means that the math has to indicate we
    # want to scale down for at least 36 hours before we
    # really shrink the pod.
    #
    # We're not trying to save pennies here. We are trying
    # to make sure we respond to natural cluster growth.
    - --scale-down-delay=36h
    
    # Scale up as quickly as within ~10m of a new node booting up, if necessary.
    - --scale-up-delay=10m
    
    # At no point should we assume the cluster is less than 10
    # nodes... this keeps us scaled up enough for any starting
    # off cluster.
    - --minClusterSize=10
    
    # https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/proposals/scalability_tests.md
    - --cpu=250m
    - --extra-cpu=4m
    
    # Memory is more dependent on number of pods than it is
    # number of nodes, and since the pod/node density changes a
    # bit, we pick the worst case scenario.
    #
    # This query:
    #   ( max(container_memory_working_set_bytes{job="kubelet", metrics_path="/metrics/cadvisor", container="cluster-autoscaler", image!=""})
    #     / sum(kube_node_info{})) / 1024 / 1024
    #
    # Shows the worst case to be around 12Mi/Node, but the
    # average to be ~6Mi/node. So we're picking ~12Mi/node to
    # be extremely cautious.
    - --extra-memory=12Mi
    - --memory=512Mi

serviceAccount:
  # -- (`bool`) Whether or not to create the node-local-dns ServiceAccount.
  create: true

  # -- (`map`) Annotations to add to the ServiceAccount.
  annotations: {}

  # -- (`string`) Optional hard-coded override for the name of the ServiceAccount.
  name: ""

# -- (`map`) Configure the deployment strategy for the pods, to ensure we don't
# roll out too many at once.
updateStrategy:
  rollingUpdate:
    maxUnavailable: 10%


# -- (`int`) Number of Cluster-Autoscaler pods to run for redundancy.
# **Note: Only one takes action at a time**
replicas: 2

# -- (`map`) Configuration for the PodDisruptionBudget
podDisruptionBudget:
  maxUnavailable: 1

# -- (`map`) Configures the Pod nodeAffinity rules
nodeAffinity: {}

# -- (`map`) Map that controls which nodes this daemonset is applied to.
nodeSelector:
  # pod-nanny is only amd64
  kubernetes.io/arch: amd64

podSecurityPolicy:
  # -- (`bool`) Whether or not to create a PodSecurityPolicy that grants the
  # Cluster-Autoscaler pods access to the /etc/ssl/certs/ca-bundle.crt file.
  #
  # ref: https://github.com/kubernetes/autoscaler/tree/cluster-autoscaler-1.13.5/cluster-autoscaler/cloudprovider/aws#common-notes-and-gotchas
  create: true

# -- (`map`) Configures which tolerations this pod will accept.
tolerations: []

# -- (`map`) Annotations to add to the Pods themselves.
podAnnotations: {}

# -- (`map`) The default configuration that caches around ~10k items is
# supposed to use ~30Mi of memory at max according to the documentation:
#
# https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/#setting-memory-limits
#
resources:
  # limit: no limit here, we do not want to pre-emptively crash the pod due to an OOM issue for any reason.
  #
  # According to
  # https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/#setting-memory-limits,
  # we should explicitly NOT let this pod get OOM'd aggressively because while
  # it is down, DNS lookups on the host will fail until it comes back. It only
  # removes the iptables routes on shutdown when it is shut down gracefully.
  requests:
    cpu: 30m
    memory: 50Mi

# -- (`string`) Required clusterName field to enable auto-discovery of the managed nodegroups
clusterName:

# -- (`string`) The path on the underlying EC2 hosts that the
# `.Values.caBundle` file can be found at. This is used for both the file
# mount, and the PodSecurityPolicy allowedHostPaths setting.
sslPath: /etc/ssl/certs

# -- (`string`) Path to the CA Bundle on the underlying EC2 hosts.
#
# Default value here is Bottlerocket specific. This is combined with the
# `.Values.sslPath` setting for the final fully qualified filename.
#
caBundle: ca-bundle.crt

# -- (`strings[]`) List of Command Line Args passed into the `cluster-autoscaler` binary
args:
  # https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-are-the-parameters-to-ca
  - --v=4
  - --stderrthreshold=info
  - --skip-nodes-with-local-storage=false
      
  # Type of node group expander to be used in scale up.
  #
  # https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-are-expanders
  - --expander=least-waste
      
  # Cloud provider type.
  - --cloud-provider=aws
      
  # How long after scale up that scale down evaluation resumes
  - --scale-down-delay-after-add=30m
      
  # https://aws.github.io/aws-eks-best-practices/cluster-autoscaling/#reducing-the-scan-interval
  # https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/proposals/scalability_tests.md#expected-performance
  #
  # 30s is the interval that the CA team uses to benchmark the app anyways
  - --scan-interval=30s
      
  # Customizations
  - --skip-nodes-with-system-pods=false
      
  # Detect similar node groups and balance the number of nodes between them
  #
  # (we want to let the spot group scale up more for example)
  - --balance-similar-node-groups=false
